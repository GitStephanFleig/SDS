{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "\n",
    "data_folder = Path(r'C:\\Users\\Sarah\\Documents\\GitHub\\Exam project_Sarah\\LatestNewsClassifiermaster\\03. Feature Engineering\\Pickles')\n",
    "\n",
    "path_df = data_folder/'df.pickle'\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)\n",
    "\n",
    "# features_train\n",
    "path_features_train = data_folder/\"features_train.pickle\"\n",
    "with open(path_features_train, 'rb') as data:\n",
    "    features_train = pickle.load(data)\n",
    "\n",
    "# labels_train\n",
    "path_labels_train = data_folder/\"labels_train.pickle\"\n",
    "with open(path_labels_train, 'rb') as data:\n",
    "    labels_train = pickle.load(data)\n",
    "\n",
    "# features_test\n",
    "path_features_test = data_folder/\"features_test.pickle\"\n",
    "with open(path_features_test, 'rb') as data:\n",
    "    features_test = pickle.load(data)\n",
    "\n",
    "# labels_test\n",
    "path_labels_test = data_folder/\"labels_test.pickle\"\n",
    "with open(path_labels_test, 'rb') as data:\n",
    "    labels_test = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the dimension of our feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15352, 100)\n",
      "(6580, 100)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can see what hyperparameters the model has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'algorithm': 'auto',\n",
      " 'leaf_size': 30,\n",
      " 'metric': 'minkowski',\n",
      " 'metric_params': None,\n",
      " 'n_jobs': None,\n",
      " 'n_neighbors': 5,\n",
      " 'p': 2,\n",
      " 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "knnc_0 =KNeighborsClassifier()\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(knnc_0.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll tune the following ones:\n",
    "\n",
    "* `K`: Number of neighbors to use by default for queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, since there is only one hyperparameter, we'll perform an exhaustive search directly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid \n",
    "n_neighbors = [int(x) for x in np.linspace(start = 1, stop = 500, num = 100)]\n",
    "\n",
    "param_grid = {'n_neighbors': n_neighbors}\n",
    "\n",
    "# Create a base model\n",
    "knnc = KNeighborsClassifier()\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=knnc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters turn out to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The best hyperparameters from Grid Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the grid had a space of 5 between each element, we'll now cover all the possible `n_neighbors` near to 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "param_grid = {'n_neighbors': n_neighbors}\n",
    "\n",
    "knnc = KNeighborsClassifier()\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=knnc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "grid_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters turn out to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best hyperparameters from Grid Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model in `best_knnc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knnc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know the best KNN model. Let's fit it and see how it performs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit the model to our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knnc.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnc_pred = best_knnc.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conditional class probabilities can be obtained by typing:\n",
    "\n",
    "`knnc_pred = best_knnc.predict_proba(features_test)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance analysis, we will use the confusion matrix, the classification report and the accuracy on both training and test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, best_knnc.predict(features_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, knnc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,knnc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_df = df[['Party', 'Republican']].drop_duplicates().sort_values('Republican')\n",
    "conf_matrix = confusion_matrix(labels_test, knnc_pred)\n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            xticklabels=aux_df['Party'].values, \n",
    "            yticklabels=aux_df['Party'].values,\n",
    "            cmap=\"Blues\")\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we could get the average time the model takes to get predictions. We want the algorithm to be fast since we are creating an app which will gather data from the internet and get the predicted categories. However, since the difference when predicting 10-20 observations will be very little, we won't take this into account.\n",
    "\n",
    "However, the code below could do this task:\n",
    "\n",
    "```python\n",
    "features_time = features_train\n",
    "elapsed_list = []\n",
    "for i in range(0,10):\n",
    "    \n",
    "    start = time.time()\n",
    "    predictions = best_lrc.predict(features_time)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    elapsed_list.append(elapsed)\n",
    "\n",
    "mean_time_elapsed = np.mean(elapsed_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the hyperparameter tuning process has returned a better model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = KNeighborsClassifier()\n",
    "base_model.fit(features_train, labels_train)\n",
    "accuracy_score(labels_test, base_model.predict(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knnc.fit(features_train, labels_train)\n",
    "accuracy_score(labels_test, best_knnc.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the default model (with 5 Nearest Neighbors) performs better. However, in our Grid Search Cross Validation process we tried with that number of neighbors. The reason why we may be getting this result is because de Grid Search performs a Cross Validation scheme, while this last comparison uses all training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a dataset with a model summary to compare models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "     'Model': 'KNN',\n",
    "     'Training Set Accuracy': accuracy_score(labels_train, best_knnc.predict(features_train)),\n",
    "     'Test Set Accuracy': accuracy_score(labels_test, knnc_pred)\n",
    "}\n",
    "\n",
    "df_models_knnc = pd.DataFrame(d, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_knnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model and this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Models/best_knnc.pickle', 'wb') as output:\n",
    "    pickle.dump(best_knnc, output)\n",
    "\n",
    "with open('Models/df_models_knnc.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_knnc, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
